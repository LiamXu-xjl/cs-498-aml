{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import expit\n",
    "\n",
    "from utils import test_case_checker, perform_computation, show_test_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the MNIST data (http://yann.lecun.com/exdb/mnist/) is stored in a binary format, we would rather have an API handle the loading for us. \n",
    "\n",
    "Pytorch (https://pytorch.org/) is an Automatic Differentiation library that we may see and use later in the course. \n",
    "\n",
    "Torchvision (https://pytorch.org/docs/stable/torchvision/index.html?highlight=torchvision#module-torchvision) is an extension library for pytorch that can load many of the famous data sets painlessly. \n",
    "\n",
    "We already used Torchvision for downloading the MNIST data. It is stored in a numpy array file that we will load easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('mnist.npz'):\n",
    "    npzfile = np.load('mnist.npz')\n",
    "    train_images_raw = npzfile['train_images_raw']\n",
    "    train_labels = npzfile['train_labels']\n",
    "    eval_images_raw = npzfile['eval_images_raw']\n",
    "    eval_labels = npzfile['eval_labels']\n",
    "else:\n",
    "    import torchvision\n",
    "    download_ = not os.path.exists('./mnist')\n",
    "    data_train = torchvision.datasets.MNIST('mnist', train=True, transform=None, target_transform=None, download=download_)\n",
    "    data_eval = torchvision.datasets.MNIST('mnist', train=False, transform=None, target_transform=None, download=download_)\n",
    "\n",
    "    train_images_raw = data_train.data.numpy()\n",
    "    train_labels = data_train.targets.numpy()\n",
    "    eval_images_raw = data_eval.data.numpy()\n",
    "    eval_labels = data_eval.targets.numpy()\n",
    "\n",
    "    np.savez('mnist.npz', train_images_raw=train_images_raw, train_labels=train_labels, \n",
    "             eval_images_raw=eval_images_raw, eval_labels=eval_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_flip_prob = 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the function `get_thresholded_and_noised` that does image thresholding and flipping pixels. More specifically, this functions should exactly apply the following two steps in order:\n",
    "\n",
    "1. **Thresholding**: First, given the input threshold argument, you must compute a thresholded image array. This array should indicate whether each element of `images_raw` is **greater than or equal to**  the `threshold` argument. We will call the result of this step the thresholded image.\n",
    "2. **Noise Application (i.e., Flipping Pixels)**: After the image was thresholded, you should use the `flip_flags` input argument and flip the pixels with a corresponding `True` entry in `flip_flags`. \n",
    "\n",
    "  * `flip_flags` mostly consists of `False` entries, which means you should not change their corresponding pixels. Instead, whenever a pixel had a `True` entry in `flip_flags`, that pixel in the thresholded image must get flipped. This way you will obtain the noised image.\n",
    "3. **Mapping Pixels to -1/+1**: You need to make sure the output image pixels are mapped to -1 and 1 values (as opposed to 0/1 or True/False).\n",
    "\n",
    "`get_thresholded_and_noised` should take the following arguments:\n",
    "\n",
    "1. `images_raw`: A numpy array. Do not assume anything about its shape, dtype or range of values. Your function should be careless about these attributes.\n",
    "2. `threshold`: A scalar value.\n",
    "3. `flip_flags`: A numpy array with the same shape as `images_raw` and `np.bool` dtype. This array indicates whether each pixel should be flipped or not.\n",
    "\n",
    "and return the following:\n",
    "\n",
    "* `mapped_noised_image`: A numpy array with the same shape as `images_raw`.  This array's entries should either be -1 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7a43224809fd8d0963612527c0b97c7",
     "grade": false,
     "grade_id": "cell-8537fe703ac9bd5d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_thresholded_and_noised(images_raw, threshold, flip_flags):\n",
    "    \n",
    "    # your code here\n",
    "    thresholded = (images_raw >= threshold)\n",
    "    np.invert(thresholded, out=thresholded, where=flip_flags>0)\n",
    "    mapped_noised_image = -1 * np.ones_like(thresholded)\n",
    "    mapped_noised_image[thresholded] = 1\n",
    "    \n",
    "    assert (np.abs(mapped_noised_image)==1).all()\n",
    "    return mapped_noised_image.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d437b2f579e514e2afb64f057b9b7cc",
     "grade": true,
     "grade_id": "cell-a93db968174effe4",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reference and solution images are the same to a T! Well done on this test case.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Enter nothing to go to the next image\n",
      "or\n",
      "    Enter \"s\" when you are done to recieve the three images. \n",
      "        **Don't forget to do this before continuing to the next step.**\n",
      "s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_thresh_noise(x, seed = 12345, p = noise_flip_prob, threshold = 128):        \n",
    "    np_random = np.random.RandomState(seed=seed)\n",
    "    flip_flags = (np_random.uniform(0., 1., size=x.shape) < p)\n",
    "    return get_thresholded_and_noised(x, threshold, flip_flags)\n",
    "\n",
    "(orig_image, ref_image, test_im, success_thr) = show_test_cases(test_thresh_noise, task_id='1_V')\n",
    "\n",
    "assert success_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ddfa2bdbc3cdfaccac1c378121cc61d",
     "grade": true,
     "grade_id": "cell-cad4a05d0f97d19d",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(get_thresholded_and_noised, task_id=1)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Applying Thresholding and Noise to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    X_true_grayscale = train_images_raw[:10, :, :]\n",
    "\n",
    "    np_random = np.random.RandomState(seed=12345)\n",
    "    flip_flags = flip_flags = (np_random.uniform(0., 1., size=X_true_grayscale.shape) < noise_flip_prob)\n",
    "    initial_pi = np_random.uniform(0, 1, size=X_true_grayscale.shape) # Initial Random Pi values\n",
    "\n",
    "    X_true = get_thresholded_and_noised(X_true_grayscale, threshold=128, flip_flags=flip_flags * 0)\n",
    "    X_noised = get_thresholded_and_noised(X_true_grayscale, threshold=128, flip_flags=flip_flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a funciton named `sigmoid_2x` that given a variable $X$ computes the following:\n",
    "\n",
    "$$f(X) := \\frac{\\exp(X)}{\\exp(X) + \\exp(-X)}$$\n",
    "\n",
    "The input argument is a numpy array $X$, which could have any shape. Your output array must have the same shape as $X$.\n",
    "\n",
    "**Important Note**: Theoretically, $f$ satisfies the following equations:\n",
    "\n",
    "$$\\lim_{X\\rightarrow +\\infty} f(X) = 1$$\n",
    "$$\\lim_{X\\rightarrow -\\infty} f(X) = 0$$\n",
    "\n",
    "Your implementation must also work correctly even on these extreme edge cases. In other words, you must satisfy the following tests.\n",
    "* `sigmoid_2x(np.inf)==1` \n",
    "* `sigmoid_2x(-np.inf)==0`.\n",
    "\n",
    "**Hint**: You may find `scipy.special.expit` useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9467e4711dfb00723c4a04f641d3a4bb",
     "grade": false,
     "grade_id": "cell-baba53895e886588",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_2x(X):\n",
    "    \n",
    "    # your code here\n",
    "    output = expit(2*X)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05703316807b847b94777d150f813ef1",
     "grade": true,
     "grade_id": "cell-4e87b3b9548c3052",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sigmoid_2x(+np.inf) == 1.\n",
    "assert sigmoid_2x(-np.inf) == 0.\n",
    "assert np.array_equal(sigmoid_2x(np.array([0, 1])).round(3), np.array([0.5, 0.881]))\n",
    "\n",
    "\n",
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(sigmoid_2x, task_id=2)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Applying Mean-field Approximation to Boltzman Machine's Variational Inference Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">Task 3</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a `boltzman_meanfield` function that applies the mean-field approximation to the Boltzman machine. \n",
    "\n",
    "Recalling the textbook notation, $X_i$ is the observed value of pixel $i$, and $H_i$ is the true value of pixel $i$ (before applying noise). For instance, if we have a $3 \\times 3$ image, the corresponding Boltzman machine looks like this: \n",
    "\n",
    "```\n",
    "       X_1        X_2        X_3\n",
    "      /          /          /\n",
    "     H_1 ------ H_2 ------ H_3\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      | X_4      | X_5      | X_6\n",
    "      |/         |/         |/ \n",
    "     H_4 ------ H_5 ------ H_6\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      |          |          |\n",
    "      | X_7      | X_8      | X_9\n",
    "      |/         |/         |/ \n",
    "     H_7 ------ H_8 ------ H_9\n",
    "```     \n",
    "\n",
    "Here, we a adopt a slightly simplified notation from the textbook and define $\\mathcal{N}(i)$ to be the neighbors of pixel $i$ (the pixels adjacent to pixel $i$). For instance, in the above figure, we have $\\mathcal{N}(1) = \\{2,4\\}$, $\\mathcal{N}(2) = \\{1,3,5\\}$, and $\\mathcal{N}(5) = \\{2,4,6,8\\}$.\n",
    "\n",
    "\n",
    "With this, the process in the textbook can be summarized as follows:\n",
    "\n",
    "```\n",
    "1. for iteration = 1, 2, 3, ....,\n",
    "  2. Pick a random pixel i.\n",
    "  3. Find pixel i's new parameter as\n",
    "```\n",
    "$$\\pi_i^{\\text{new}} = \\frac{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))}{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1)) + \\exp(-\\theta_{ii}^{(2)} X_i - \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))} .$$\n",
    "```\n",
    "  4. Replace the existing parameter for pixel i with the new one.\n",
    "```\n",
    "$$\\pi_i \\leftarrow \\pi_i^{\\text{new}}$$\n",
    "\n",
    "Since our computational resources are extremely vectorized, we will make the following minor algorithmic modification and ask you to implement the following instead:\n",
    "\n",
    "```\n",
    "1. for iteration = 1, 2, 3, ....,\n",
    "  2. for each pixels i:\n",
    "  3. Find pixel i's new parameter, but do not update the original parameter yet.\n",
    "```\n",
    "$$\\pi_i^{\\text{new}} = \\frac{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))}{\\exp(\\theta_{ii}^{(2)} X_i + \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1)) + \\exp(-\\theta_{ii}^{(2)} X_i - \\sum_{j\\in \\mathcal{N}(i)} \\theta_{ij}^{(1)} (2\\pi_j -1))} .$$\n",
    "```\n",
    "  4. Once you have computed all the new parameters, update all of them at the same time:\n",
    "```\n",
    "$$\\pi \\leftarrow \\pi^{\\text{new}}$$\n",
    "\n",
    "We assume that the parameters $\\theta_{ii}^{(2)}$ have the same value for all $i$ and denote their common value by scalar `theta_X`. Moreover, we assume that the parameters $\\theta_{ij}^{(1)}$ have the same value for all $i,j$ and denote their common value by scalar `theta_pi`.\n",
    "\n",
    "The `boltzman_meanfield` function must take the following input arguments:\n",
    "1. `images`: A numpy array with the shape `(N,height,width)`, where \n",
    "    * `N` is the number of samples and could be anything,\n",
    "    * `height` is each individual image's height in pixels (i.e., number of rows in each image),\n",
    "    * and `width` is each individual image's width in pixels (i.e., number of columns in each image).\n",
    "      * Do not assume anything about `images`'s dtype or the number of samples or the `height` or the `width`.\n",
    "      * The entries of `images` are either -1 or 1.\n",
    "2. `initial_pi`: A numpy array with the same shape as `images` (i.e. `(N,height,width)`). This variable is corresponding to the initial value of $\\pi$ in the textbook analysis and above equations. Note that for each of the $N$ images, we have a different $\\pi$ variable.\n",
    "\n",
    "3. `theta_X`: A scalar with a default value of `0.5*np.log(1/noise_flip_prob-1)`. This variable represents $\\theta_{ii}^{(2)}$ in the above update equation.\n",
    "\n",
    "4. `theta_pi`: A scalar with a default value of 2. This variable represents $\\theta_{ij}^{(1)}$ in the above update equation.\n",
    "\n",
    "5. `iterations`: A scalar with a default value of 100. This variable denotes the number of update iterations to perform.\n",
    "\n",
    "The `boltzman_meanfield` function must return the final $\\pi$ variable as a numpy array called `pi`, and should contain values that are between 0 and 1. \n",
    "\n",
    "**Hint**: You may find the `sigmoid_2x` function, that you implemented earlier, useful.\n",
    "\n",
    "**Hint**: If you want to find the summation of neighboring elements for all of a 2-dimensional matrix, there is an easy and efficient way using matrix operations. You can initialize a zero matrix, and then add four shifted versions (i.e., left-, right-, up-, and down-shifted versions) of the original matrix to it. You will have to be careful in the assignment and selection indices, since you will have to drop one row/column for each shifted version of the matrix.\n",
    "  * Do **not** use `np.roll` if you're taking this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0cd68da6ffa91cc0796f53f49b7ab71a",
     "grade": false,
     "grade_id": "cell-e47949a00f04759c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boltzman_meanfield(images, initial_pi, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=2, iterations=100):\n",
    "    if len(images.shape)==2:\n",
    "        # In case a 2d image was given as input, we'll add a dummy dimension to be consistent\n",
    "        X = images.reshape(1,*images.shape)\n",
    "    else:\n",
    "        # Otherwise, we'll just work with what's given\n",
    "        X = images\n",
    "    \n",
    "    pi = initial_pi\n",
    "    # your code here\n",
    "    \n",
    "    \n",
    "    return pi.reshape(*images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5753989d3e0dad787a6833c39262fb89",
     "grade": true,
     "grade_id": "cell-6291d0a80ccca660",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_boltzman(x, seed = 12345, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=2, iterations=100):        \n",
    "    np_random = np.random.RandomState(seed=seed)\n",
    "    initial_pi = np_random.uniform(0,1, size=x.shape)\n",
    "    return boltzman_meanfield(x, initial_pi, theta_X=theta_X, \n",
    "                              theta_pi=theta_pi, iterations=iterations)\n",
    "    \n",
    "(orig_image, ref_image, test_im, success_is_row_inky) = show_test_cases(test_boltzman, task_id='3_V')\n",
    "\n",
    "assert success_is_row_inky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dfbdbd77c48ab7c23ce00913b90050b8",
     "grade": true,
     "grade_id": "cell-e7b59624d7ab9ec3",
     "locked": true,
     "points": 0.8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Checking against the pre-computed test database\n",
    "test_results = test_case_checker(boltzman_meanfield, task_id=3)\n",
    "assert test_results['passed'], test_results['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tuning the Boltzman Machine's Hyper-Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the `boltzman_meanfield` function that you implemented above, here see the effect of changing hyper parameters `theta_X` and `theta_pi` which were defined in Task 3. \n",
    "\n",
    "- We set `theta_X` to be `0.5*np.log(1/noise_flip_prob-1)` where `noise_flip_prob` was the probability of flipping each pixel. Try to think why this is a reasonable choice. (This is also related to one of the questions in the follow-up quiz).\n",
    "- We try different values for `theta_pi`. \n",
    "\n",
    "For each value of `theta_pi`, we the apply the denoising and compare the denoised images to the original ones. We adopt several statistical measures to compare original and denoised images and to finally decide which value of `theta_pi` is better. Remember that during the noising process, we chose some pixels and decide to flip them, and during the denoising process we essentially try to detect such pixels. Let `P` be the total number of pixels that we flip during the noise adding process, and `N` be the total number of pixels that we do not flip during the noise adding process. We can define:\n",
    "\n",
    "- True Positive (`TP`). Defined to be the total number of pixels that are flipped during the noise adding process, and we successfully detect them during the denoising process. \n",
    "- True Positive Rate (`TPR`). Other names: sensitivity, recall. Defined to be the ratio `TP / P`.\n",
    "- False Positive (`FP`). Defined to be the number of pixels that were detected as being noisy during the denosing process, but were not really noisy. \n",
    "- False Positive Rate (`FPR`). Other name: fall-out. Defined to be the ratio `FP/N`.\n",
    "- Positive Predictive Value (`PPV`). Other name: precision. Defined to be the ratio `TP / (TP + FP)`.\n",
    "- `F1` score. Defined to be the harmonic mean of precision (`PPV`) and recall (`TPR`), or equivalently `2 TP / (2 TP + FP + FN)`. \n",
    "\n",
    "Since we fix `theta_X` in this section and evaluate different values of `theta_pi`, in the plots, `theta` refers to `theta_pi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr(preds, true_labels):\n",
    "    TP = (preds * (preds == true_labels)).sum()\n",
    "    P = true_labels.sum()\n",
    "    if P==0:\n",
    "        TPR = 1.\n",
    "    else:\n",
    "        TPR = TP / P\n",
    "    \n",
    "    return TPR\n",
    "\n",
    "def get_fpr(preds, true_labels):\n",
    "    FP = (preds * (preds != true_labels)).sum()\n",
    "    N = (1-true_labels).sum()\n",
    "    if N==0:\n",
    "        FPR=1\n",
    "    else:\n",
    "        FPR = FP / N\n",
    "    return FPR\n",
    "\n",
    "def get_ppv(preds, true_labels):\n",
    "    TP = (preds * (preds == true_labels)).sum()\n",
    "    FP = (preds * (preds != true_labels)).sum()\n",
    "    if (TP + FP) == 0:\n",
    "        PPV = 1\n",
    "    else:\n",
    "        PPV = TP / (TP + FP)\n",
    "    return PPV\n",
    "\n",
    "def get_f1(preds, true_labels):\n",
    "    TP = (preds * (preds == true_labels)).sum()\n",
    "    FP = (preds * (preds != true_labels)).sum()\n",
    "    FN = ((1-preds) * (preds != true_labels)).sum()\n",
    "    if (2 * TP + FP + FN) == 0:\n",
    "        F1 = 1\n",
    "    else:\n",
    "        F1 = (2 * TP) / (2 * TP + FP + FN)\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    all_theta = np.arange(0, 10, 0.2).tolist() + np.arange(10, 100, 5).tolist()\n",
    "\n",
    "    tpr_list, fpr_list, ppv_list, f1_list = [], [], [], []\n",
    "\n",
    "    for theta in all_theta:\n",
    "        meanfield_pi = boltzman_meanfield(X_noised, initial_pi, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=theta, iterations=100)\n",
    "        X_denoised = 2 * (meanfield_pi > 0.5) - 1\n",
    "\n",
    "        predicted_noise_pixels = (X_denoised != X_noised)\n",
    "        tpr = get_tpr(predicted_noise_pixels, flip_flags)\n",
    "        fpr = get_fpr(predicted_noise_pixels, flip_flags)\n",
    "        ppv = get_ppv(predicted_noise_pixels, flip_flags)\n",
    "        f1 = get_f1(predicted_noise_pixels, flip_flags)\n",
    "\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        ppv_list.append(ppv)\n",
    "        f1_list.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4), dpi=90)\n",
    "\n",
    "    ax=axes[0]\n",
    "    ax.plot(all_theta, tpr_list)\n",
    "    ax.set_xlabel('Theta')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('True Positive Rate Vs. Theta')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    ax=axes[1]\n",
    "    ax.plot(all_theta, fpr_list)\n",
    "    ax.set_xlabel('Theta')\n",
    "    ax.set_ylabel('False Positive Rate')\n",
    "    ax.set_title('False Positive Rate Vs. Theta')\n",
    "    ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,3), dpi=90)\n",
    "\n",
    "    ax=axes[0]\n",
    "    ax.plot(fpr_list, tpr_list)\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('ROC Curve')\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.plot(np.arange(-0.05, 1.05, 0.01), np.arange(-0.05, 1.05, 0.01), ls='--', c='black')\n",
    "\n",
    "    ax=axes[1]\n",
    "    ax.plot(all_theta, f1_list)\n",
    "    ax.set_xlabel('Theta')\n",
    "    ax.set_ylabel('F1-statistic')\n",
    "    ax.set_title('F1-score Vs. Theta')\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "    ax=axes[2]\n",
    "    ax.plot(tpr_list, ppv_list)\n",
    "    ax.set_xlabel('Recall')\n",
    "    ax.set_ylabel('Precision')\n",
    "    ax.set_title('Precision Vs. Recall')\n",
    "    ax.set_xlim(-0.05, 1.05)\n",
    "    ax.set_ylim(-0.05, 1.05)\n",
    "    ax.plot(np.arange(-0.05, 1.05, 0.01), 1-np.arange(-0.05, 1.05, 0.01), ls='--', c='black')\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    best_theta = all_theta[np.argmax(f1_list)]\n",
    "    print(f'Best theta w.r.t. the F-score is {best_theta}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the tuned hyper-parameters, and verify whether it visually improved the Boltzman machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ffddbff83f528b6590d47a23414c8dd",
     "grade": true,
     "grade_id": "cell-00c232dc99ca3fdd",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if perform_computation:\n",
    "    def test_boltzman(x, seed = 12345, theta_X=0.5*np.log(1/noise_flip_prob-1), theta_pi=best_theta, iterations=100):        \n",
    "        np_random = np.random.RandomState(seed=seed)\n",
    "        initial_pi = np_random.uniform(0,1, size=x.shape)\n",
    "        return boltzman_meanfield(x, initial_pi, theta_X=theta_X, \n",
    "                                  theta_pi=theta_pi, iterations=iterations) >  0.5\n",
    "\n",
    "    (orig_image, ref_image, test_im, success_is_row_inky) = show_test_cases(test_boltzman, task_id='4_V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
